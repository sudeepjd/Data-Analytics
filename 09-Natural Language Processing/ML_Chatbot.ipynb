{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMJMZZ/Ev9yV2jL/3miYPA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudeepjd/Data-Analytics/blob/master/09-Natural%20Language%20Processing/ML_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sbCUf1qS9LB",
        "colab_type": "text"
      },
      "source": [
        "# Simple Machine Learning Chatbot using SVM Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQfhLXSgGq1u",
        "colab_type": "text"
      },
      "source": [
        "## Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI1UESWyGez2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import urllib\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# nltk.download('punkt')"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71-SdrwRG5DG",
        "colab_type": "text"
      },
      "source": [
        "## Load the Intents File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_mSnQe2RkIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = urllib.request.urlopen(\"https://raw.githubusercontent.com/sudeepjd/Data-Analytics/master/09-Natural%20Language%20Processing/mlchat_intents.json\")\n",
        "data = json.loads(file.read())"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d3UEUT6HEF7",
        "colab_type": "text"
      },
      "source": [
        "Extract the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AJe1j_JHK7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs_x = []\n",
        "docs_y = []"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGq7NdACHFt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = LancasterStemmer()\n",
        "for intent in data['intents']:\n",
        "\tfor pattern in intent['patterns']:\n",
        "\t\twrds = nltk.word_tokenize(pattern)\n",
        "\t\twrds = [stemmer.stem(w.lower()) for w in wrds if w != \"?\"]\n",
        "\t\tdocs_x.append(' '.join(wrds))\n",
        "\t\tdocs_y.append(intent[\"tag\"])"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ukpb2AF6J0-",
        "colab_type": "text"
      },
      "source": [
        "Vectorize X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm0c8R98IAhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "fabf234e-7393-4f25-f275-cc40550180cb"
      },
      "source": [
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(docs_x).toarray()\n",
        "print(X)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EtMaUR_6MCR",
        "colab_type": "text"
      },
      "source": [
        "Vectorize Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e42L6yZQ6S4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "34db62b6-b327-4219-da4b-a0c9159d6f8a"
      },
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(docs_y)\n",
        "print(y)\n",
        "print (le.inverse_transform([6]))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 6  6  6  6  8  8  8  8  5  5  5  5 14 14 14  7  7  7  7  7  7  9  9  9\n",
            "  9  9  9 12 12 12 13 13 15 15 15 16 10 10 10 10 11 11 11  0  0  0  0  1\n",
            "  1  1  2  2  2  3  3  3  4  4  4  4  4]\n",
            "['greeting']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRHf2Ex78LRs",
        "colab_type": "text"
      },
      "source": [
        "## Build and Train the Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t8lfnog8YRc",
        "colab_type": "text"
      },
      "source": [
        "Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-1Fg9-l8OQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "adcf388c-8f5e-4d85-c2dc-7ec37b07906f"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel='linear')\n",
        "classifier.fit(X, y)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY3qYD449DsI",
        "colab_type": "text"
      },
      "source": [
        "Predict Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F_-XDGp9Am1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def provide_response(sent):\n",
        "  #Pre-Process Input\n",
        "  sent = nltk.word_tokenize(sent)\n",
        "  sent = [stemmer.stem(w.lower()) for w in sent if w != \"?\"]\n",
        "  sent = [' '.join(sent)]\n",
        "  X_pred = cv.transform(sent).toarray()\n",
        "\n",
        "  #Predict\n",
        "  y_pred = classifier.predict(X_pred)\n",
        "  tag = le.inverse_transform(y_pred)\n",
        "  tag = tag[0]\n",
        "\n",
        "  #Get the options to respond\n",
        "  for tg in data['intents']:\n",
        "    if tg['tag'] == tag:\n",
        "      responses = tg['responses']\n",
        "\n",
        "  #Return one of them\n",
        "  return (tag, random.choice(responses))"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loU3W4VYBVPL",
        "colab_type": "text"
      },
      "source": [
        "Test Single Response"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4t_umYqAk-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8a22fbca-232f-49d0-92f3-dad24cd8083f"
      },
      "source": [
        "print(provide_response(\"What can I do with regression?\"))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('regression', 'In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships between a dependent variable and one or more independent variables')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe4OPKJNBZBn",
        "colab_type": "text"
      },
      "source": [
        "## Execute the Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk5CfzEoCwqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0tqIKgsBcOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "7d585d9d-bd22-4622-863b-0cb861907b84"
      },
      "source": [
        "print (\"BOT : Hello! I am ML Chat.\")\n",
        "\n",
        "while True:\n",
        "  inp = input(\"\\nYOU : \")\n",
        "  resp = provide_response(inp)\n",
        "  \n",
        "  print(\"\\nBOT : \" + resp[1])\n",
        "  \n",
        "  if resp[0] == \"goodbye\" : break"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOT : Hello! I am ML Chat.\n",
            "\n",
            "YOU : deep learning\n",
            "\n",
            "BOT : Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making. \n",
            "It can be used both for regression as well as for classification problems.\n",
            "\n",
            "YOU : bye\n",
            "\n",
            "BOT : Bye! Come back again soon.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}