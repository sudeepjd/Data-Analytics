{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPzoVPtV/v7wOdE+PbF7tSA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudeepjd/Data-Analytics/blob/master/09-Natural%20Language%20Processing/ML_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sbCUf1qS9LB",
        "colab_type": "text"
      },
      "source": [
        "# Simple Machine Learning Chatbot using SVM Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQfhLXSgGq1u",
        "colab_type": "text"
      },
      "source": [
        "## Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI1UESWyGez2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import urllib\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71-SdrwRG5DG",
        "colab_type": "text"
      },
      "source": [
        "## Load the Intents File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_mSnQe2RkIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = urllib.request.urlopen(\"https://raw.githubusercontent.com/sudeepjd/Data-Analytics/master/09-Natural%20Language%20Processing/mlchat_intents.json\")\n",
        "data = json.loads(file.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d3UEUT6HEF7",
        "colab_type": "text"
      },
      "source": [
        "Extract the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AJe1j_JHK7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs_x = []\n",
        "docs_y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGq7NdACHFt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = LancasterStemmer()\n",
        "for intent in data['intents']:\n",
        "\tfor pattern in intent['patterns']:\n",
        "\t\twrds = nltk.word_tokenize(pattern)\n",
        "\t\twrds = [stemmer.stem(w.lower()) for w in wrds if w != \"?\"]\n",
        "\t\tdocs_x.append(' '.join(wrds))\n",
        "\t\tdocs_y.append(intent[\"tag\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ukpb2AF6J0-",
        "colab_type": "text"
      },
      "source": [
        "Vectorize X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm0c8R98IAhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(docs_x).toarray()\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EtMaUR_6MCR",
        "colab_type": "text"
      },
      "source": [
        "Vectorize Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e42L6yZQ6S4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(docs_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRHf2Ex78LRs",
        "colab_type": "text"
      },
      "source": [
        "## Build and Train the Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t8lfnog8YRc",
        "colab_type": "text"
      },
      "source": [
        "Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-1Fg9-l8OQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel='linear')\n",
        "classifier.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY3qYD449DsI",
        "colab_type": "text"
      },
      "source": [
        "Predict Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F_-XDGp9Am1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def provide_response(sent):\n",
        "  #Pre-Process Input\n",
        "  sent = nltk.word_tokenize(sent)\n",
        "  sent = [stemmer.stem(w.lower()) for w in sent if w != \"?\"]\n",
        "  sent = [' '.join(sent)]\n",
        "  X_pred = cv.transform(sent).toarray()\n",
        "\n",
        "  #Predict\n",
        "  y_pred = classifier.predict(X_pred)\n",
        "  tag = le.inverse_transform(y_pred)\n",
        "  tag = tag[0]\n",
        "\n",
        "  #Get the options to respond\n",
        "  for tg in data['intents']:\n",
        "    if tg['tag'] == tag:\n",
        "      responses = tg['responses']\n",
        "\n",
        "  #Return one of them\n",
        "  return (tag, random.choice(responses))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loU3W4VYBVPL",
        "colab_type": "text"
      },
      "source": [
        "Test Single Response"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4t_umYqAk-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(provide_response(\"What can I do with regression?\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe4OPKJNBZBn",
        "colab_type": "text"
      },
      "source": [
        "## Execute the Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0tqIKgsBcOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"BOT : Hello! I am ML Chat.\")\n",
        "\n",
        "while True:\n",
        "  inp = input(\"\\nYOU : \")\n",
        "  resp = provide_response(inp)\n",
        "  \n",
        "  print(\"\\nBOT : \" + resp[1])\n",
        "  \n",
        "  if resp[0] == \"goodbye\" : break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}